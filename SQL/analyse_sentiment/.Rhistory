?cor
install.packages("ISLR")
library("ISLR")
college
data <- college
data <- data(college)
data <- data(College)
College
View(College)
O[1,] <- c(0,3,0)
?matrix
O <- matrix(data = NA, nrow = 6,ncol =3)
O[1,] <- c(0,3,0)
O[2,] <- c(2,0,0)
O[3.] <- c(0,1,3)
O[4,] <- c(0,1,2)
O[5,] <- c(-1,0,1)
O[6,] <- c(1,1,1)
O
O <- matrix(data = NA, nrow = 6,ncol =3)
O[1,] <- c(0,3,0)
O[2,] <- c(2,0,0)
O[3,] <- c(0,1,3)
O[4,] <- c(0,1,2)
O[5,] <- c(-1,0,1)
O[6,] <- c(1,1,1)
Otest <- c(0,0,0)
for (i in seq(1:6))
{
eudistance[i] <- sum((Otest - O[i,])^2)
}
O <- matrix(data = NA, nrow = 6,ncol =3)
eudistance <- matrix(data = NA,nrow = 6,ncol=1)
O[1,] <- c(0,3,0)
O[2,] <- c(2,0,0)
O[3,] <- c(0,1,3)
O[4,] <- c(0,1,2)
O[5,] <- c(-1,0,1)
O[6,] <- c(1,1,1)
Otest <- c(0,0,0)
for (i in seq(1:6))
{
eudistance[i] <- sum((Otest - O[i,])^2)
}
O <- matrix(data = NA, nrow = 6,ncol =3)
eudistance <- matrix(data = NA,nrow = 6,ncol=1)
O[1,] <- c(0,3,0)
O[2,] <- c(2,0,0)
O[3,] <- c(0,1,3)
O[4,] <- c(0,1,2)
O[5,] <- c(-1,0,1)
O[6,] <- c(1,1,1)
Otest <- c(0,0,0)
for (i in seq(1:6))
{
eudistance[i] <- sum((Otest - O[i,])^2)
}
eudistance
O <- matrix(data = NA, nrow = 6,ncol =3)
eudistance <- matrix(data = NA,nrow = 6,ncol=1)
O[1,] <- c(0,3,0)
O[2,] <- c(2,0,0)
O[3,] <- c(0,1,3)
O[4,] <- c(0,1,2)
O[5,] <- c(-1,0,1)
O[6,] <- c(1,1,1)
Otest <- c(0,0,0)
for (i in seq(1:6))
{
eudistance[i] <- sqrt(sum((Otest - O[i,])^2))
}
eudistance
expression<- read.table('expressions_train.txt')
I<-matrix(expression[1,],60,70)
I1 <- apply(I, 1, rev)
image(matrix(unlist(I1),ncol=70,byrow=TRUE),col=gray(0:255 / 255))
?colSums
library(klaR)
?NaiveBayes
Auto <- read.table("Auto.data",header=T,na.string="?")
View(Auto)
attach(Auto)
lm.fit = lm(mpg ~ horsepower)
summary(lm.fit)
#how strong is the relationship:
meany <- mean(Auto[,1])
#how strong is the relationship:
meany <- mean(Auto[,1])
RSE <- 4.906
persontage.error <- 100*RSE/meany
predict(lm.fit, data.frame(horsepower=c(98)), interval="confidence")
predict(lm.fit, data.frame(horsepower=c(98)), interval="prediction")
predict(lm.fit, data.frame(horsepower=c(98)), interval="prediction")
plot(horsepower, mpg)
abline(lm.fit)
par(mfrow=c(2,2))
plot(lm.fit)
pairs(Auto)
cor(subset(Auto, select=-name))
lm.fit1 = lm(mpg~.-name, data=Auto)
summary(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit1)
plot(predict(lm.fit1), rstudent(lm.fit1))
lm.fit2 = lm(mpg~cylinders*displacement+displacement*weight)
summary(lm.fit2)
library(ISLR)
attach(Carseats)
lm.fit = lm(Sales~Price+Urban+US)
summary(lm.fit)
View(Carseats)
lm.fit2 = lm(Sales ~ Price + US)
summary(lm.fit2)
plot(predict(lm.fit2), rstudent(lm.fit2))
par(mfrow=c(2,2))
plot(lm.fit2)
set.seed(1)
x = rnorm(100)
y = 2*x + rnorm(100)
lm.fit = lm(y~x+0)
summary(lm.fit)
lm.fit = lm(x~y+0)
summary(lm.fit)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
set.seed(1)
x = rnorm(100)
eps = rnorm(100, 0, sqrt(0.25))
y = -1 + 0.5*x + eps
plot(x, y)
lm.fit = lm(y~x)
summary(lm.fit)
plot(x, y)
abline(lm.fit, lwd=3, col=2)
abline(-1, 0.5, lwd=3, col=3)
legend(-1, legend = c("model fit", "pop. regression"), col=2:3, lwd=3)
lm.fit_sq = lm(y~x+I(x^2))
summary(lm.fit_sq)
cor(x1,x2)
set.seed(1)
x1 = runif(100)
x2 = 0.5 * x1 + rnorm(100)/10
y = 2 + 2*x1 + 0.3*x2 + rnorm(100)
cor(x1,x2)
lm.fit = lm(y~x1+x2)
summary(lm.fit)
lm.fit = lm(y~x1)
summary(lm.fit)
lm.fit = lm(y~x2)
summary(lm.fit)
x1 = c(x1, 0.1)
x2 = c(x2, 0.8)
y = c(y, 6)
lm.fit1 = lm(y~x1+x2)
summary(lm.fit1)
par(mfrow=c(2,2))
plot(lm.fit1)
library(MASS)
attach(Boston)
lm.all = lm(crim~., data=Boston)
summary(lm.all)
setwd("~/Desktop/prplot")
pd=read.csv("nbpositive_favorite.csv",header=T,na.strings ="?")
x <- pd[,2]
y <- pd[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de favorite')
pf=read.csv("nbpositive_favorite.csv",header=T,na.strings ="?")
x <- pf[,2]
y <- pf[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de favorite')
pl=read.csv("nbpositive_likecount.csv",header=T,na.strings ="?")
x <- pl[,2]
y <- pl[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de like')
nd=read.csv("nbnegative_dislike.csv",header=T,na.strings ="?")
x <- nd[,2]
y <- nd[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de dislike')
nf=read.csv("nbnegative_favorite.csv",header=T,na.strings ="?")
x <- nf[,2]
y <- nf[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de favorite')
nl=read.csv("nbnegative_like.csv",header=T,na.strings ="?")
x <- nl[,2]
y <- nl[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de like')
pd=read.csv("nbpositive_dislike.csv",header=T,na.strings ="?")
x <- pd[,2]
y <- pd[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de dislike')
pf=read.csv("nbpositive_favorite.csv",header=T,na.strings ="?")
x <- pf[,2]
y <- pf[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de favorite')
pl=read.csv("nbpositive_likecount.csv",header=T,na.strings ="?")
x <- pl[,2]
y <- pl[,3]
plot(x,y,xlab = 'Nombre de commentaires positives',ylab='Espérance de nombre de like')
nd=read.csv("nbnegative_dislike.csv",header=T,na.strings ="?")
x <- nd[,2]
y <- nd[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de dislike')
nf=read.csv("nbnegative_favorite.csv",header=T,na.strings ="?")
x <- nf[,2]
y <- nf[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de favorite')
nl=read.csv("nbnegative_like.csv",header=T,na.strings ="?")
x <- nl[,2]
y <- nl[,3]
plot(x,y,xlab = 'Nombre de commentaires négatives',ylab='Espérance de nombre de like')
